{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36. 23. 16.  9. 65. 36. 23.  3. 16.  9.  2.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "validation loss of epoch 1:2.778009026887224\n",
      "validation loss of epoch 2:2.5797960140334784\n",
      "validation loss of epoch 3:2.5205491305367715\n",
      "validation loss of epoch 4:2.486284067307279\n",
      "validation loss of epoch 5:2.461709832215152\n",
      "validation loss of epoch 6:2.443355613024452\n",
      "validation loss of epoch 7:2.4283048534219356\n",
      "validation loss of epoch 8:2.416231710713091\n",
      "validation loss of epoch 9:2.4060014460052366\n",
      "validation loss of epoch 10:2.3968322834728375\n",
      "tensor(-6.7309, grad_fn=<SelectBackward0>)\n",
      "tensor([[38]])\n",
      "tensor(-11.5954, grad_fn=<SelectBackward0>)\n",
      "tensor([[17]])\n",
      "tensor(-9.4121, grad_fn=<SelectBackward0>)\n",
      "tensor([[10]])\n",
      "tensor(-10.0508, grad_fn=<SelectBackward0>)\n",
      "tensor([[16]])\n",
      "tensor(-9.1301, grad_fn=<SelectBackward0>)\n",
      "tensor([[65]])\n",
      "tensor(-8.2083, grad_fn=<SelectBackward0>)\n",
      "tensor([[30]])\n",
      "tensor(-11.8175, grad_fn=<SelectBackward0>)\n",
      "tensor([[3]])\n",
      "tensor(-11.5907, grad_fn=<SelectBackward0>)\n",
      "tensor([[20]])\n",
      "tensor(-12.8741, grad_fn=<SelectBackward0>)\n",
      "tensor([[22]])\n",
      "tensor(-14.3139, grad_fn=<SelectBackward0>)\n",
      "tensor([[2]])\n",
      "tensor(-15.1288, grad_fn=<SelectBackward0>)\n",
      "tensor([[7]])\n",
      "tensor(-11.0606, grad_fn=<SelectBackward0>)\n",
      "tensor([[20]])\n",
      "tensor(-10.9385, grad_fn=<SelectBackward0>)\n",
      "tensor([[2]])\n",
      "tensor(-12.5835, grad_fn=<SelectBackward0>)\n",
      "tensor([[2]])\n",
      "tensor(-14.2248, grad_fn=<SelectBackward0>)\n",
      "tensor([[7]])\n",
      "tensor(-11.1365, grad_fn=<SelectBackward0>)\n",
      "tensor([[20]])\n",
      "tensor(-11.1468, grad_fn=<SelectBackward0>)\n",
      "tensor([[2]])\n",
      "tensor(-12.6353, grad_fn=<SelectBackward0>)\n",
      "tensor([[2]])\n",
      "tensor(-14.2411, grad_fn=<SelectBackward0>)\n",
      "tensor([[7]])\n",
      "tensor(-11.3313, grad_fn=<SelectBackward0>)\n",
      "tensor([[20]])\n",
      "Argmax:  John Bart.er..er..er\n",
      "Random:\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([5.4759e-08, 4.6107e-08, 3.6238e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.3482e-07, 1.5594e-07, 2.3469e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([5.1888e-08, 5.8351e-08, 9.5123e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([3.7135e-08, 4.0061e-08, 3.4982e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([2.3589e-07, 2.3608e-07, 3.0198e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([8.7630e-08, 6.6025e-08, 3.5852e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([2.9080e-07, 2.6086e-07, 2.5554e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([2.7837e-08, 3.1016e-08, 9.7901e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.4375e-08, 1.2432e-08, 1.1335e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([8.7773e-09, 8.4618e-09, 7.6723e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.5224e-09, 4.9117e-09, 5.7083e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.3533e-09, 1.5175e-09, 2.5304e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([3.1155e-08, 2.8082e-08, 1.3265e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([5.4962e-08, 3.5288e-08, 5.6188e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([6.1109e-09, 8.4077e-09, 4.9762e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.7358e-09, 1.8818e-09, 3.3540e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.7087e-08, 4.2195e-08, 2.0119e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.2016e-07, 8.0664e-08, 7.7208e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([7.3768e-09, 8.0153e-09, 3.8170e-01], grad_fn=<SliceBackward0>)\n",
      "Tarn Tohny..ert.en.o\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([2.0391e-08, 1.8665e-08, 2.0410e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([8.8653e-10, 1.2567e-09, 1.9159e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([2.6157e-07, 3.3164e-07, 6.9779e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.7489e-07, 1.7814e-07, 2.6215e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1398e-08, 9.4113e-09, 1.0824e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([4.7092e-10, 6.1303e-10, 1.1403e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1012e-10, 1.9368e-10, 2.7715e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([9.7968e-09, 1.1191e-08, 4.7228e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([2.8100e-08, 3.7599e-08, 8.2631e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1417e-08, 1.3396e-08, 4.6289e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([6.6505e-10, 8.5011e-10, 1.6293e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.0896e-08, 2.0198e-08, 1.1547e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([9.0588e-07, 6.5250e-07, 7.3086e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.2120e-08, 1.2046e-08, 9.8269e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([3.8958e-08, 3.5077e-08, 1.3820e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1043e-07, 9.5065e-08, 8.2530e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.0630e-08, 1.1647e-08, 6.1947e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.3746e-09, 1.5329e-09, 2.4374e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.6732e-08, 4.8069e-08, 1.2563e-01], grad_fn=<SliceBackward0>)\n",
      "Gri Bttias.ezmey..iv\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([2.0391e-08, 1.8665e-08, 2.0410e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([9.3782e-07, 6.4980e-07, 2.2515e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.3177e-07, 1.1761e-07, 8.9359e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.4002e-08, 1.5117e-08, 1.5453e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.4737e-07, 1.5981e-07, 2.9169e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([8.6169e-09, 1.1962e-08, 5.5634e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([3.7934e-07, 3.8767e-07, 4.3888e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([5.3685e-07, 5.3840e-07, 1.9202e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1001e-07, 9.1156e-08, 7.9297e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([4.7500e-06, 3.4693e-06, 3.7917e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([1.0485e-07, 8.2461e-08, 2.0033e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.8755e-09, 2.9582e-09, 1.9887e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.0422e-09, 1.3922e-09, 1.4810e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.5185e-08, 1.8143e-08, 9.0308e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([2.5213e-08, 2.2832e-08, 1.9554e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1449e-09, 1.5453e-09, 3.7614e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.2928e-10, 5.8817e-10, 1.8856e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.4333e-08, 1.7685e-08, 1.3519e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.4738e-08, 2.0058e-08, 4.7583e-01], grad_fn=<SliceBackward0>)\n",
      "Gerwis Alest.arg.an.\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([1.3662e-09, 1.4582e-09, 2.3841e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([8.4265e-08, 7.3049e-08, 7.4893e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([9.1754e-08, 9.2433e-08, 4.3742e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.0743e-08, 1.1671e-08, 6.0506e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([4.0103e-08, 3.4562e-08, 1.5399e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([3.2467e-07, 3.0060e-07, 3.8123e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.5060e-08, 1.5274e-08, 4.0244e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([6.3962e-08, 9.7401e-08, 4.4158e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([5.3275e-09, 6.3724e-09, 5.0366e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([6.8667e-09, 7.9324e-09, 1.6439e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.7435e-08, 2.9271e-08, 1.8499e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.7432e-08, 1.7379e-08, 6.1766e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.9954e-08, 2.9570e-08, 3.6201e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1060e-08, 1.1955e-08, 7.4682e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.5730e-08, 1.8607e-08, 2.2509e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([6.2429e-08, 4.4358e-08, 8.4227e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([8.0254e-09, 8.4313e-09, 4.8958e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.6695e-09, 1.8888e-09, 1.8477e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.5126e-08, 1.8049e-08, 8.7314e-02], grad_fn=<SliceBackward0>)\n",
      "Velly Rashi.oson..a.\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([4.1428e-09, 3.7348e-09, 1.2995e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([2.9367e-09, 4.2100e-09, 1.6488e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([9.7008e-10, 1.3397e-09, 8.0231e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([3.9336e-08, 4.3307e-08, 2.8692e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([3.5319e-08, 3.3490e-08, 1.8024e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([2.0535e-08, 2.0142e-08, 4.3325e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([2.7626e-07, 2.7336e-07, 4.1893e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([8.2998e-08, 1.3818e-07, 1.7577e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([3.4539e-08, 5.5467e-08, 3.8711e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1602e-09, 2.0929e-09, 3.0188e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([8.7733e-10, 1.0017e-09, 7.1138e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([4.2007e-10, 5.2819e-10, 9.5279e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([2.9388e-07, 2.7845e-07, 2.1680e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([5.2891e-07, 4.8195e-07, 6.6758e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([5.0846e-09, 7.3741e-09, 4.6223e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.0513e-09, 2.2753e-09, 2.8158e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.2024e-09, 8.6859e-09, 3.7519e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([1.9527e-08, 3.5558e-08, 2.4937e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([3.3764e-08, 3.5462e-08, 2.2903e-01], grad_fn=<SliceBackward0>)\n",
      "Carfel Qutmle.t.Scki\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([7.4275e-07, 6.8610e-07, 6.4217e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([2.2896e-07, 2.8994e-07, 1.8507e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1878e-08, 1.7963e-08, 9.8676e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([4.2237e-09, 5.5523e-09, 2.3100e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.5721e-09, 1.9891e-09, 1.4607e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([2.9557e-07, 3.1524e-07, 3.1860e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.2654e-07, 1.2134e-07, 3.4367e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([5.9296e-08, 7.4772e-08, 6.6703e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([2.9841e-07, 2.9710e-07, 3.4655e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.2761e-07, 1.6784e-07, 9.2442e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([3.5240e-08, 4.4407e-08, 1.3502e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.0723e-08, 3.7336e-08, 2.2298e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([3.1391e-08, 2.4469e-08, 6.0150e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.6219e-09, 4.9962e-09, 4.4736e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([7.5081e-08, 6.2724e-08, 2.9866e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([8.6168e-08, 7.8336e-08, 6.6488e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.6428e-09, 2.8630e-09, 3.2516e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([5.7403e-08, 5.0636e-08, 1.8204e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([6.4899e-09, 8.2096e-09, 4.0396e-01], grad_fn=<SliceBackward0>)\n",
      "Ooshlenn oyin.e..eg.\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([2.5581e-10, 2.2354e-10, 1.7097e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.2882e-08, 1.7140e-08, 4.9238e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.3312e-08, 1.4597e-08, 3.6667e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([5.1577e-08, 5.5909e-08, 7.9196e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.6019e-07, 1.4727e-07, 4.5940e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.5415e-09, 1.2612e-09, 1.5034e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.4823e-08, 1.2640e-08, 2.8366e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([3.2444e-09, 3.1024e-09, 1.8153e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([6.2209e-10, 7.4857e-10, 5.4842e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([7.2810e-10, 1.2132e-09, 2.1823e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([7.3711e-09, 1.0938e-08, 2.6129e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.7375e-08, 2.1928e-08, 6.3556e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([9.0272e-09, 8.4572e-09, 5.4443e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([5.3713e-09, 5.2469e-09, 4.2764e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([6.8241e-08, 5.7796e-08, 2.6399e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1990e-07, 1.1047e-07, 6.7366e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.9880e-09, 3.2228e-09, 3.2696e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.3309e-09, 4.3142e-09, 2.5787e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.4925e-07, 1.5135e-07, 1.6968e-03], grad_fn=<SliceBackward0>)\n",
      "Dilo Fendsannde..n L\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([2.5581e-10, 2.2354e-10, 1.7097e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([3.6199e-09, 4.8019e-09, 3.6640e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([2.5072e-09, 4.6548e-09, 6.6367e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1818e-08, 1.4575e-08, 1.1465e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.0610e-07, 1.0182e-07, 3.1401e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([3.7276e-09, 4.4414e-09, 5.1207e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([3.8345e-09, 4.2408e-09, 1.2997e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.9684e-08, 3.1707e-08, 1.9380e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([8.3052e-08, 6.4904e-08, 4.8726e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.5170e-08, 2.2788e-08, 5.7530e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.8597e-07, 1.4232e-07, 3.8803e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.5439e-07, 1.3649e-07, 6.7329e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.1517e-09, 4.2795e-09, 3.1013e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.3325e-08, 4.7464e-08, 1.1791e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.7911e-06, 1.3877e-06, 6.2520e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.6687e-07, 1.5846e-07, 3.2262e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.6467e-07, 2.5865e-07, 2.1858e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([8.0008e-08, 7.0214e-08, 2.1131e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([3.2062e-07, 3.2299e-07, 3.2465e-01], grad_fn=<SliceBackward0>)\n",
      "Davi dyor.e..oz.araz\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([2.1941e-08, 1.6039e-08, 4.4633e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([3.4238e-07, 3.5699e-07, 4.5597e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.0562e-07, 1.1758e-07, 6.3342e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([3.3391e-07, 3.1206e-07, 2.4550e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([3.1776e-07, 1.5654e-07, 1.1279e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([1.5015e-06, 1.1157e-06, 4.1217e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.0724e-06, 1.2250e-06, 1.3919e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([4.8377e-08, 4.8741e-08, 5.2366e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([1.8082e-08, 1.5461e-08, 6.0023e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([4.5549e-09, 4.4059e-09, 5.2193e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.2200e-09, 1.2861e-09, 2.1410e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.9087e-08, 2.4290e-08, 5.1423e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([1.3600e-07, 2.0898e-07, 6.9737e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([1.8709e-07, 1.5606e-07, 2.5080e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.2629e-08, 1.2597e-08, 3.9730e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.3215e-09, 1.5586e-09, 1.5884e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([2.9762e-08, 2.7193e-08, 1.2266e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([5.5835e-08, 3.6630e-08, 5.2879e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1180e-08, 1.0196e-08, 4.9136e-01], grad_fn=<SliceBackward0>)\n",
      "Joh Jobmy..ucis.er.s\n",
      "tensor([9.3974e-07, 7.8994e-07, 2.4382e-05], grad_fn=<SliceBackward0>)\n",
      "tensor([8.8945e-09, 8.2134e-09, 2.5546e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.3120e-09, 2.1120e-09, 4.0463e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([9.0694e-09, 1.0378e-08, 6.2695e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([1.7667e-07, 1.7173e-07, 3.1345e-04], grad_fn=<SliceBackward0>)\n",
      "tensor([1.2948e-08, 1.5587e-08, 3.6821e-03], grad_fn=<SliceBackward0>)\n",
      "tensor([5.7659e-09, 5.9956e-09, 1.7195e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([3.3656e-08, 3.5475e-08, 9.5354e-02], grad_fn=<SliceBackward0>)\n",
      "tensor([1.0004e-07, 1.2228e-07, 1.2965e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.1341e-07, 8.7278e-08, 5.7168e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([3.8407e-07, 3.5358e-07, 4.8801e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([5.8914e-08, 6.3417e-08, 4.2643e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([8.6208e-09, 9.8617e-09, 2.0395e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([7.1857e-08, 6.6892e-08, 1.2292e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.6162e-08, 1.5458e-08, 1.5064e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([1.7347e-09, 1.7447e-09, 4.3365e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([3.6415e-07, 3.1466e-07, 3.5121e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([6.0801e-07, 3.9037e-07, 4.3122e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([3.7105e-07, 2.5108e-07, 7.9111e-01], grad_fn=<SliceBackward0>)\n",
      "tensor([3.1754e-08, 3.2198e-08, 3.9192e-01], grad_fn=<SliceBackward0>)\n",
      "Bry iliank..elleen..\n",
      "{0: '', 1: '<bos>', 2: '.', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z', 29: 'A', 30: 'B', 31: 'C', 32: 'D', 33: 'E', 34: 'F', 35: 'G', 36: 'H', 37: 'I', 38: 'J', 39: 'K', 40: 'L', 41: 'M', 42: 'N', 43: 'O', 44: 'P', 45: 'Q', 46: 'R', 47: 'S', 48: 'T', 49: 'U', 50: 'V', 51: 'W', 52: 'X', 53: 'Y', 54: 'Z', 55: '0', 56: '1', 57: '2', 58: '3', 59: '4', 60: '5', 61: '6', 62: '7', 63: '8', 64: '9', 65: ' '}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "# import tqdm\n",
    "\n",
    "\n",
    "def get_vocab():\n",
    "    # Construct the character 'vocabulary'\n",
    "    # we allow lowercase, uppercase and digits only, along with special characters:\n",
    "    # \"\" - Empty string used to denote elements for the RNN to ignore\n",
    "    # \"<bos>\" - Beginning of sequence token for the input the the RNN\n",
    "    # \".\" - End of sequence token\n",
    "    vocab = [\"\", \"<bos>\", \".\"] + list(string.ascii_lowercase + string.ascii_uppercase + string.digits + \" \")\n",
    "    id_to_char = {i: v for i, v in enumerate(vocab)} # maps from ids to characters\n",
    "    char_to_id = {v: i for i, v in enumerate(vocab)} # maps from characters to ids\n",
    "    return vocab, id_to_char, char_to_id\n",
    "\n",
    "def load_data(filename):\n",
    "    # read in the list of names\n",
    "    data = json.load(open(filename, \"r\"))\n",
    "    # append the end of sequence token to each name\n",
    "    data = [v+'.' for v in data]\n",
    "    return data\n",
    "\n",
    "def seqs_to_ids(seqs, char_to_id, max_len=20):\n",
    "    \"\"\"Takes a list of names and turns them into a list of tokens ids.\n",
    "    Responsible for padding sequences shorter than max_len with 0 so that all sequences are max_len.\n",
    "    Also truncates names that are longer than max_len.\n",
    "    Should also skip empty sequences if there are any.\n",
    "\n",
    "    Args:\n",
    "        seqs (list(str)): A list of names as strings.\n",
    "        char_to_id (dict(str : int)): The mapping for characters to token ids\n",
    "        max_len (int, optional): The maximum length of the ouput sequence. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        np.array: the names represented using token ids as 2d numpy array, \n",
    "            where each row corresponds to a name. The size of the array should be N * max_len\n",
    "            where N is the number of non-empty sequences input. Padded with zeros if needed.\n",
    "    \"\"\"\n",
    "    all_seqs = []\n",
    "    # TODO: implement this function to turn a list of names into a 2d padded array of token ids\n",
    "    if seqs!=[]:\n",
    "        for name in seqs:\n",
    "                seq=np.zeros((max_len))\n",
    "                n=min(len(name),max_len)\n",
    "                for i in range(n):\n",
    "                    seq[i]=char_to_id[name[i]]\n",
    "                all_seqs.append(seq)\n",
    "    print(all_seqs[0])\n",
    "    return np.array(all_seqs)\n",
    "\n",
    "\n",
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size = 32, gru_size=32):\n",
    "        super(RNNLM, self).__init__()\n",
    "\n",
    "        # store layer sizes\n",
    "        self.emb_size = emb_size\n",
    "        self.gru_size = gru_size\n",
    "\n",
    "        # for embedding characters (ignores those with value 0: the padded values)\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size, padding_idx=0)\n",
    "        # GRU layer\n",
    "        self.gru = nn.GRU(emb_size, gru_size, batch_first=True)\n",
    "        # linear layer for output\n",
    "        self.linear = nn.Linear(gru_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x, h_last=None):\n",
    "        \"\"\"Takes a batch of names/sequences expressed as token ids and passes them through the GRU.\n",
    "            The output is the predicted (un-normalized) probabilities of \n",
    "            the next token for all prefixes of the input sequences.\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): A 2d tensor of longs giving the token ids for each batch. Shape B * S\n",
    "                where B is the batch size (any batch size >= 1 is permitted), S is the length of the sequence.\n",
    "            h_last (torch.tensor, optional): A 2d float tensor of size B * G where B is the batch size and G\n",
    "                is the dimensionality of the GRU hidden state. The hidden state from the previous step, provide only if \n",
    "                generating sequences iteratively. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            tuple(torch.tensor, torch.tensor): first element of the tuple is the B * S * V where V is the vocabulary size.\n",
    "                This is the logit output of the RNNLM. The second element is the hidden state of the final step\n",
    "                of the GRU it should be B * G dimensional.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: implement this function which does the forward pass of the RNNLM network\n",
    "        # out = None; h = None # TODO: remove this line.\n",
    "        em=self.emb(x)\n",
    "        gr,h=self.gru(em,h_last)\n",
    "        out=self.linear(gr)\n",
    "        return out, h\n",
    "\n",
    "        \n",
    "def train_model(model, Xtrain, Ytrain, Xval, Yval, id_to_char, max_epoch):\n",
    "    \"\"\"Train the RNNLM model using the Xtrain and Ytrain examples.\n",
    "    Uses mini-batch stochastic gradient descent with the Adam optimizer on \n",
    "    the mean cross entropy loss. Prints out the validation loss\n",
    "    after each epoch using calc_val_loss.\n",
    "\n",
    "    Args:\n",
    "        model (RNNLM): the RNNLM model.\n",
    "        Xtrain (torch.tensor): The training data input sequence of size Nt * S. \n",
    "            Nt is the number of training examples, S is the sequence length. \n",
    "            The sequences always start with the <bos> token id.\n",
    "            The rest of the sequence is just Ytrain shifted to the right one position.\n",
    "            The sequence is zero padded.\n",
    "        Ytrain (torch.tensor): The expected output sequence of size Nt * S. \n",
    "            Does not start with the <bos> token.\n",
    "        Xval (torch.tensor): The validation data input sequence of size Nv * S. \n",
    "            Nv is the number of validation examples, S is the sequence length. \n",
    "            The sequences always start with the <bos> token id.\n",
    "            The rest of sequence is just Yval shifted to the right one position.\n",
    "            The sequence is zero padded.\n",
    "        Yval (torch.tensor): The expected output sequence for the validation data of size Nv * S. \n",
    "            Does not start with the <bos> token. Is zero padded.\n",
    "        id_to_char (dict(int : str)): A mapping from ids to tokens.\n",
    "        max_epoch (int): the maximum number of epochs to train for.\n",
    "    \"\"\"\n",
    "    # construct the adam optimizer\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    # construct the cross-entropy loss function\n",
    "    # we want to ignore padding cells with value == 0\n",
    "    lossfn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    # calculate number of batches\n",
    "    batch_size = 32\n",
    "    num_batches = int(Xtrain.shape[0] / batch_size)\n",
    "\n",
    "    # run the main training loop over many epochs\n",
    "    for e in range(max_epoch):\n",
    "\n",
    "        # TODO: implement the training loop of the RNNLM model\n",
    "        for i in range(num_batches+1):\n",
    "            st=i*batch_size\n",
    "            en=(i+1)*batch_size\n",
    "            if en> Xtrain.shape[0]:\n",
    "                en = Xtrain.shape[0]\n",
    "            y_h=model(Xtrain[st:en])[0].permute(0,2,1)\n",
    "            y_t=Ytrain[st:en]\n",
    "            loss=lossfn(y_h,y_t)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        c=calc_val_loss(model,Xval,Yval)\n",
    "        print(f\"validation loss of epoch {e+1}:{c}\")\n",
    "        pass\n",
    "\n",
    "\n",
    "def gen_string(model, id_to_char, max_len=20, sample=True):\n",
    "    \"\"\"Generate a name using the model. The generation process should finish once\n",
    "    the end token is seen. We either sample from the model, where the next token is\n",
    "    chosen randomly according to the categorical probability distribution produced by softmax,\n",
    "    or we use argmax decoding where the most likely token is chosen at every generation step.\n",
    "\n",
    "    Args:\n",
    "        model (RNNLM): The trained RNNLM model.\n",
    "        id_to_char (dict(int, str)): A mapping from token ids to token strings.\n",
    "        max_len (int, optional): The maximum length of the output sequence. Defaults to 20.\n",
    "        sample (bool, optional): If True then generate samples. If False then use argmax decoding. \n",
    "            Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated name as a string.\n",
    "    \"\"\"\n",
    "    # put the model into eval mode because we don't need gradients\n",
    "    model.eval()\n",
    "\n",
    "    # setup the initial input to the network\n",
    "    # we will use a batch size of one for generation\n",
    "    h = torch.zeros((1,1,model.gru_size), dtype=torch.float) # h0 is all zeros\n",
    "    x = torch.ones((1, 1), dtype=torch.long) # x is the <bos> token id which = 1\n",
    "    out_str = \"\"\n",
    "    # generate the sequence step by step\n",
    "    for i in range(max_len):\n",
    "\n",
    "        # TODO: implement the generation loop of the RNNLM model\n",
    "        #       this should generate a name from the model\n",
    "        #       using either sampling or argmax decoding \n",
    "        \n",
    "        out,h1=model(x,h)\n",
    "        # print(out)\n",
    "        if sample==True:\n",
    "            out=out.softmax(dim=2)\n",
    "            print(out[0,0,0:3])\n",
    "            x=torch.multinomial(out[0,0],1).reshape((1,1))\n",
    "        else:\n",
    "            print(out[0,0,0])\n",
    "            x=out.argmax(dim=2)\n",
    "            print(x)\n",
    "        h=h1\n",
    "            # print(id_to_char[int(x[0,0])])\n",
    "        out_str+=id_to_char[int(x)]\n",
    "        pass\n",
    "\n",
    "    # set the model back to training mode in case we need gradients later\n",
    "    model.train()\n",
    "\n",
    "    return out_str\n",
    "\n",
    "\n",
    "def calc_val_loss(model, Xval, Yval):\n",
    "    \"\"\"Calculates the validation loss in average nats per character.\n",
    "\n",
    "    Args:\n",
    "        model (RNNLM): the RNNLM model.\n",
    "        Xval (torch.tensor): The validation data input sequence of size B * S. \n",
    "            B is the batch size, S is the sequence length. The sequences always start with the <bos> token id.\n",
    "            The rest of sequence is just Yval shifted to the right one position.\n",
    "            The sequence is zero padded.\n",
    "        Yval (torch.tensor): The expected output sequence for the validation data of size B * S. \n",
    "            Does not start with the <bos> token. Is zero padded.\n",
    "\n",
    "    Returns:\n",
    "        float: validation loss in average nats per character.\n",
    "    \"\"\"\n",
    "\n",
    "    # use cross entropy loss\n",
    "    lossfn = nn.CrossEntropyLoss(ignore_index=0, reduction='sum')\n",
    "\n",
    "    # put the model into eval mode because we don't need gradients\n",
    "    model.eval()\n",
    "\n",
    "    # calculate number of batches, we need to be precise this time\n",
    "    batch_size = 32\n",
    "    num_batches = int(Xval.shape[0] / batch_size)\n",
    "    if Xval.shape[0] % batch_size != 0:\n",
    "        num_batches += 1\n",
    "\n",
    "    # sum up the total loss\n",
    "    total_loss = 0\n",
    "    total_chars = 0\n",
    "    for n in range(num_batches):\n",
    "\n",
    "        # calculate batch start end idxs \n",
    "        s = n * batch_size\n",
    "        e = (n+1)*batch_size\n",
    "        if e > Xval.shape[0]:\n",
    "            e = Xval.shape[0]\n",
    "\n",
    "        # compute output of model        \n",
    "        out,_ = model(Xval[s:e])\n",
    "\n",
    "        # compute loss and store\n",
    "        loss = lossfn(out.permute(0, 2, 1), Yval[s:e]).detach().cpu().numpy()\n",
    "        total_loss += loss\n",
    "\n",
    "        char_count = torch.count_nonzero(Yval[s:e].flatten())\n",
    "        total_chars += char_count.detach().cpu().numpy()\n",
    "\n",
    "    # compute average loss per character\n",
    "    total_loss /= total_chars\n",
    "    \n",
    "    # set the model back to training mode in case we need gradients later\n",
    "    model.train()\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def main():\n",
    "    # load the data from disk\n",
    "    data = load_data(os.path.join(\"data\", \"names_small.json\"))\n",
    "\n",
    "    # get the letter 'vocabulary'\n",
    "    vocab, id_to_char, char_to_id = get_vocab()\n",
    "    vocab_size = len(vocab)\n",
    "    \n",
    "    # convert the data into a sequence of ids which will be the target for our RNN\n",
    "    Y = seqs_to_ids(data, char_to_id)\n",
    "    # the input needs to be shifted by 1 and have the <bos> tokenid prepended to it\n",
    "    # this also means we have to remove the last element of the sequence to keep the length constant\n",
    "    #print(np.where(Y==np.array([36, 23, 16,  9, 65, 36, 23,  3, 16,  9,  2, 0,  0,  0,  0,  0,  0,  0, 0, 0])),np.shape(Y))\n",
    "    X = np.concatenate([np.ones((Y.shape[0], 1)), Y[:, :-1]], axis=1)\n",
    "\n",
    "    # split the data int training and validation\n",
    "    # convert the data into torch tensors\n",
    "    train_frac = 0.9\n",
    "    num_train = int(X.shape[0]*train_frac)\n",
    "    Xtrain = torch.tensor(X[:num_train], dtype=torch.long)\n",
    "    Ytrain = torch.tensor(Y[:num_train], dtype=torch.long)\n",
    "    Xval = torch.tensor(X[num_train:], dtype=torch.long)\n",
    "    Yval = torch.tensor(Y[num_train:], dtype=torch.long)\n",
    "\n",
    "    # train the model\n",
    "    model = RNNLM(vocab_size)\n",
    "    train_model(model, Xtrain, Ytrain, Xval, Yval, id_to_char, max_epoch=10)\n",
    "\n",
    "    # use the model to generate and print some names\n",
    "    print(\"Argmax: \", gen_string(model, id_to_char, sample=False))\n",
    "    print(\"Random:\")\n",
    "    for i in range(10):\n",
    "        gstr = gen_string(model, id_to_char)\n",
    "        print(gstr)\n",
    "    print(id_to_char)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]] [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "          2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "          4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "          5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "          6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "          7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "          8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "          9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10,\n",
       "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11,\n",
       "         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12,\n",
       "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13,\n",
       "         13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14,\n",
       "         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15,\n",
       "         15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "         17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "         18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "         19, 19, 19]),\n",
       "  array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "         19,  0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 19,  0,  1,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19,  0,  1,  2,  3,  4,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "         16, 17, 18, 19,  0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13,\n",
       "         14, 16, 17, 18, 19,  0,  1,  2,  3,  4,  6,  7,  8,  9, 11, 12, 13,\n",
       "         14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  6,  8,  9, 10, 11, 12,\n",
       "         13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  4,  6,  7,  8,  9, 10, 11,\n",
       "         12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  4,  6,  7,  8,  9, 10,\n",
       "         11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  6,  7,  8,\n",
       "         10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  6,  7,\n",
       "          8,  9, 10, 11, 12, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  6,  7,\n",
       "          8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,\n",
       "          6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 19,  0,  1,  2,  3,\n",
       "          4,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  0,  1,  2,\n",
       "          3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18, 19,  0,  1,\n",
       "          2,  3,  4,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19,  0,\n",
       "          1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18,  0,  1,  2,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19,  0,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19]))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran=np.random.multinomial(1,[1/20]*20,size=100)\n",
    "x=np.random.multinomial(1,[1/20]*20)\n",
    "print(ran,x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/vvt_b_c938b62rrq3bmkf88w0000gn/T/ipykernel_79330/4250793062.py:1: DeprecationWarning: This function is deprecated. Please call randint(1, 5 + 1) instead\n",
      "  a=np.random.random_integers(5,size=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 5, 4, 2, 4, 5, 4, 5, 5, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.random.random_integers(5,size=10)\n",
    "a[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y=np.array([[1,2],[3,4]])\n",
    "np.average(y,axis=1),y[1]\n",
    "y[[0,1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

nround = 2,
objective = linex,
eval_metric = "error")
# Make predictions
pred <- predict(model, dtest)
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
data <- read.csv("../kerala.csv")
head(data)
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(-'YEAR')
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
set.seed(123)
numOfTrain <- round(length(data_y) * 0.6)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
# Create DMatrix for xgboost
dtrain <- xgb.DMatrix(data = train_x, label = train_y)
dtest <- xgb.DMatrix(data = test_x, label = test_y)
# Train the model
model <- xgboost(data = dtrain, nround = 2, objective = "binary:logistic")
# Make predictions
pred <- predict(model, dtest)
# Calculate and print the classification error
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
# Extract model parameters
# model_dump <- xgb.dump(model, with_stats = TRUE)
#
# cat(model_dump[1:10], sep = "\n")
#
# xgb.dump(model, with_stats = TRUE, fname = "xgboost_model_dump.txt")
# custom_objective <- function(preds, dtrain) {
#   q=0.19
#   labels <- getinfo(dtrain, "label")
#   a_minus_Y <- preds - labels
#   indicator <- ifelse(a_minus_Y > 0, 1, 0)
#   grad <- (indicator - q)
#
#   hess <- rep(0.1, length(grad))
#
#   return(list(grad = grad, hess = hess))
# }
#
#
# model <- xgboost(data = dtrain,
#                  nround = 2,
#                  objective = custom_objective)
#
# # Make predictions
# pred <- predict(model, dtest)
#
# # Calculate and print the classification error
# err <- mean(as.numeric(pred > 0.5) != test_y)
# print(paste("test-error=", err))
#
linex <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
psi <- 10
z <- psi * (preds - labels)
grad <- psi*(exp(z) - 1)
hess <- (psi^2)*exp(z)
return(list(grad = grad, hess = hess))
}
# Train the model with the custom objective function
model <- xgboost(data = dtrain,
nround = 2,
objective = linex,
eval_metric = "error")
# Make predictions
pred <- predict(model, dtest)
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
model_dump <- xgb.dump(model, with_stats = TRUE)
cat(model_dump[1:10], sep = "\n")
xgb.dump(model, with_stats = TRUE, fname = "xgboost_model_dump.txt")
data <- read.csv("../kerala.csv")
head(data)
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(-'YEAR')
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
set.seed(123)
numOfTrain <- round(length(data_y) * 0.5)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
linex <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
psi <- 10
z <- psi * (preds - labels)
grad <- psi*(exp(z) - 1)
hess <- (psi^2)*exp(z)
return(list(grad = grad, hess = hess))
}
# Train the model with the custom objective function
model <- xgboost(data = dtrain,
nround = 2,
objective = linex,
eval_metric = "error")
# Make predictions
pred <- predict(model, dtest)
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
data <- read.csv("../kerala.csv")
head(data)
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(-'YEAR')
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
set.seed(123)
numOfTrain <- round(length(data_y) * 0.5)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
dtrain <- xgb.DMatrix(data = train_x, label = train_y)
dtest <- xgb.DMatrix(data = test_x, label = test_y)
linex <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
psi <- 10
z <- psi * (preds - labels)
grad <- psi*(exp(z) - 1)
hess <- (psi^2)*exp(z)
return(list(grad = grad, hess = hess))
}
# Train the model with the custom objective function
model <- xgboost(data = dtrain,
nround = 2,
objective = linex,
eval_metric = "error")
# Make predictions
pred <- predict(model, dtest)
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
linex <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
psi <- 10
z <- psi * (preds - labels)
grad <- psi*(exp(z) - 1)
hess <- (psi^2)*exp(z)
return(list(grad = grad, hess = hess))
}
# Train the model with the custom objective function
model <- xgboost(data = dtrain,
nround = 2,
objective = linex,
eval_metric = "error")
# Make predictions
pred <- predict(model, dtest)
err_tr<-mean(as.numeric(pred > 0.5) != train_y)
err_tt <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("train-error=", err_tr))
print(paste("test-error=", err_tt))
model <- xgboost(data = dtrain, nround = 2, objective = "binary:logistic")
# Make predictions
pred <- predict(model, dtest)
err_tr<-mean(as.numeric(pred > 0.5) != train_y)
err_tt <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("train-error=", err_tr))
print(paste("test-error=", err_tt))
linex <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
psi <- 0.01
z <- psi * (preds - labels)
grad <- psi*(exp(z) - 1)
hess <- (psi^2)*exp(z)
return(list(grad = grad, hess = hess))
}
# Train the model with the custom objective function
model <- xgboost(data = dtrain,
nround = 5,
objective = linex,
eval_metric = "error")
# Make predictions
pred <- predict(model, dtest)
err_tr<-mean(as.numeric(pred > 0.5) != train_y)
err_tt <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("train-error=", err_tr))
print(paste("test-error=", err_tt))
model_dump <- xgb.dump(model, with_stats = TRUE)
data <- read.csv("../kerala.csv")
head(data)
cor_matrix <- cor(data)
data <- read.csv("../kerala.csv")
head(data)
cor_matrix <- cor(data %>% select_if(is.numeric) %>%
select(-'YEAR'))
# Melt the correlation matrix
melted_cor_matrix <- melt(cor_matrix)
library(reshape2)
# Load the data
data <- read.csv("../kerala.csv")
head(data)
cor_matrix <- cor(data %>% select_if(is.numeric) %>%
select(-'YEAR'))
# Melt the correlation matrix
melted_cor_matrix <- melt(cor_matrix)
# Plot heatmap
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1, 1), space = "Lab",
name="Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1)) +
coord_fixed()
data <- read.csv("kerala.csv")
# Load the data
data <- read.csv("..\kerala.csv")
# Load the data
data <- read.csv("../kerala.csv")
head(data)
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(- YEAR)
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
# Split data into training and testing sets
set.seed(123)  # For reproducibility
numOfTrain <- round(length(data_y) * 0.7)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
# Create DMatrix for xgboost
dtrain <- xgb.DMatrix(data = train_x, label = train_y)
dtest <- xgb.DMatrix(data = test_x, label = test_y)
# Train the model
model <- xgboost(data = dtrain, nround = 2, objective = "binary:logistic")
# Make predictions
pred <- predict(model, dtest)
# Calculate and print the classification error
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
# Load the data
data <- read.csv("../kerala.csv")
head(data)
data<-data[sample(nrow(data)), ]
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(- YEAR)
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
# Split data into training and testing sets
set.seed(123)  # For reproducibility
numOfTrain <- round(length(data_y) * 0.7)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
# Create DMatrix for xgboost
dtrain <- xgb.DMatrix(data = train_x, label = train_y)
dtest <- xgb.DMatrix(data = test_x, label = test_y)
# Train the model
model <- xgboost(data = dtrain, nround = 2, objective = "binary:logistic")
# Make predictions
pred <- predict(model, dtest)
# Calculate and print the classification error
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
set.seed(123)
# Load the data
data <- read.csv("../kerala.csv")
head(data)
data<-data[sample(nrow(data)), ]
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(- YEAR)
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
numOfTrain <- round(length(data_y) * 0.7)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
# Create DMatrix for xgboost
dtrain <- xgb.DMatrix(data = train_x, label = train_y)
dtest <- xgb.DMatrix(data = test_x, label = test_y)
# Train the model
model <- xgboost(data = dtrain, nround = 2, objective = "binary:logistic")
# Make predictions
pred <- predict(model, dtest)
# Calculate and print the classification error
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
set.seed(123)
# Load the data
data <- read.csv("../kerala.csv")
head(data)
data<-data[sample(nrow(data)), ]
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(- YEAR)
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
numOfTrain <- round(length(data_y) * 0.5)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
# Create DMatrix for xgboost
dtrain <- xgb.DMatrix(data = train_x, label = train_y)
dtest <- xgb.DMatrix(data = test_x, label = test_y)
# Train the model
model <- xgboost(data = dtrain, nround = 2, objective = "binary:logistic")
# Make predictions
pred <- predict(model, dtest)
# Calculate and print the classification error
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
err_r<- mean(as.numeric(pred > 0.5) != train_y)
print(paste("test-error=", err_r))
data <- read.csv("../kerala.csv")
head(data)
data<-data[sample(nrow(data)), ]
head(data)
set.seed(42)
# Load the data
data <- read.csv("../kerala.csv")
head(data)
data<-data[sample(nrow(data)), ]
head(data)
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(- YEAR)
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
numOfTrain <- round(length(data_y) * 0.6)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
# Create DMatrix for xgboost
dtrain <- xgb.DMatrix(data = train_x, label = train_y)
dtest <- xgb.DMatrix(data = test_x, label = test_y)
# Train the model
model <- xgboost(data = dtrain, nround = 2, objective = "binary:logistic")
# Make predictions
pred <- predict(model, dtest)
# Calculate and print the classification error
err_r<- mean(as.numeric(pred > 0.5) != train_y)
print(paste("trian-error=", err_r))
err <- mean(as.numeric(pred > 0.5) != test_y)
print(paste("test-error=", err))
set.seed(42)
# Load the data
data <- read.csv("../kerala.csv")
head(data)
data<-data[sample(nrow(data)), ]
head(data)
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(- YEAR)
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
numOfTrain <- round(length(data_y) * 0.6)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
# Create DMatrix for xgboost
dtrain <- xgb.DMatrix(data = train_x, label = train_y)
dtest <- xgb.DMatrix(data = test_x, label = test_y)
# Train the model
model <- xgboost(data = dtrain, nround = 2, objective = "binary:logistic")
# Make predictions
pred_r <- predict(model, dtrain)
pred_e <- predict(model, dtest)
# Calculate and print the classification error
err_r<- mean(as.numeric(pred_r > 0.5) != train_y)
print(paste("trian-error=", err_r))
err <- mean(as.numeric(pred_e > 0.5) != test_y)
print(paste("test-error=", err))
set.seed(42)
# Load the data
data <- read.csv("../kerala.csv")
head(data)
data<-data[sample(nrow(data)), ]
head(data)
# Select numeric columns and exclude the 'YEAR' column
data_x <- data %>%
select_if(is.numeric) %>%
select(- YEAR)
head(data_x)
# Convert the selected data to a numeric matrix
mx <- data.matrix(data_x)
# Convert the 'FLOODS' column to a binary numeric vector
data_y <- ifelse(data$FLOODS == 'YES', 1, 0)
head(data_y)
data_combined <- cbind(data_x, FLOODS = data_y)
numOfTrain <- round(length(data_y) * 0.6)
train_x <- mx[1:numOfTrain, ]
train_y <- data_y[1:numOfTrain]
test_x <- mx[(numOfTrain + 1):length(data_y), ]
test_y <- data_y[(numOfTrain + 1):length(data_y)]
# Create DMatrix for xgboost
dtrain <- xgb.DMatrix(data = train_x, label = train_y)
dtest <- xgb.DMatrix(data = test_x, label = test_y)
# Train the model
model <- xgboost(data = dtrain, nround = 2, objective = "binary:logistic")
# Make predictions
pred_r <- predict(model, dtrain)
pred_e <- predict(model, dtest)
# Calculate and print the classification error
err_r<- mean(as.numeric(pred_r > 0.5) != train_y)
err_e<- mean(as.numeric(pred_e > 0.5) != test_y)
print(paste("trian-error=", err_r))
print(paste("test-error=", err_e))
# # Extract model parameters
# model_dump <- xgb.dump(model, with_stats = TRUE)
#
# cat(model_dump[1:10], sep = "\n")
#
# xgb.dump(model, with_stats = TRUE, fname = "xgboost_model_dump.txt")
custom_objective <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
q <- 0.1
a_minus_Y <- preds - labels
indicator <- ifelse(a_minus_Y > 0, 1, 0)
grad <- (indicator - q)
hess <- rep(0.1, length(grad))
return(list(grad = grad, hess = hess))
}
model <- xgboost(data = dtrain,
nround = 2,
objective = custom_objective)
err_r<- mean(as.numeric(pred_r > 0.5) != train_y)
err_e<- mean(as.numeric(pred_e > 0.5) != test_y)
print(paste("trian-error=", err_r))
print(paste("test-error=", err_e))
linex <- function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
psi <- 10
z <- psi * (preds - labels)
grad <- psi*(exp(z) - 1)
hess <- (psi^2)*exp(z)
return(list(grad = grad, hess = hess))
}
# Train the model with the custom objective function
model <- xgboost(data = dtrain,
nround = 2,
objective = linex,
eval_metric = "error")
pred_r <- predict(model, dtrain)
pred_e <- predict(model, dtest)
err_r<- mean(as.numeric(pred_r > 0.5) != train_y)
err_e<- mean(as.numeric(pred_e > 0.5) != test_y)
print(paste("trian-error=", err_r))
print(paste("test-error=", err_e))

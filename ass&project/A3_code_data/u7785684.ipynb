{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Answer1\n",
    "1, Architecture of your sentiment classifier with embedding ,dropout,linear and encorder layer  is shown below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentClassifier(\n",
      "  (token_embeddings): Embedding(38482, 300, padding_idx=0)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=300, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.5, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=300, bias=True)\n",
      "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.5, inplace=False)\n",
      "        (dropout2): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " 2, 0.8964 which was tested on google colab \n",
    " \n",
    "\\\n",
    "3, The transformer seems to show more accuracy than a logistic regression classifier with Word2Vector with limited windows showed which was around 0.86 and showed similar accuracy compared to a logistic regression classifier with tfidf which showed around 0.90. The advantage of transformer is  its accuracy but transformer toke a longer time to train because of its complex architecture which also make me confusing.And transformer may have much more hyperparameters while logistic regression classifier do not especially classifier with tfidf feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer2\n",
    "\n",
    "1, My final solution was DistilBERT model\n",
    "\n",
    "2, I split data sets into train and validation sets and the fraction is 6:1. Due to the data provided with 'Y'==0 or 3 is small ,to get a more balanced dataset I group them with 'Y' first then random sample in each group to split the data. I also applied a fine tuning which  got best performance on validation sets .I didn't apply a hyperparmeter searching function but I do try some different hyperparmeters eg. probability of dropout=0.1,0.5 learning rate =1e-5,3e-4 and so on to get an balanced training process.\n",
    "\n",
    "3,I just tested the DistilBERT model with different configurations.It seems the deafault configration works the best for it is the most complex I think.\n",
    "\n",
    "4, A proper learning rate is important 3e-4 may be to big for learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Answer3\n",
    "1, I found that the querying LLM directly make a more direct response ,however, RAG didn't and RAG dependent more on given context.And for these 2 cases since RAG need to summarize first which took longer time for generating answers.\n",
    "\n",
    "\n",
    "2,The standard retrieval runs quickly while the others runs slow.But they can provide different applications.People choose which to use depending on their needs.\n",
    "\n",
    "\n",
    "The results are below:\n",
    "\n",
    "Answer the question below in text using about 50 words, your answer should be in bullet points.\n",
    "\n",
    "Question:\n",
    "Is nuclear power plant eco-friendly?\n",
    "\n",
    "Answer:\n",
    "• No, nuclear power plants produce radioactive waste that can harm the environment and human health.\n",
    "• Nuclear accidents, such as Chernobyl and Fukushima, have caused significant environmental damage and radioactive contamination.\n",
    "• The process of extracting uranium, which is used in nuclear reactors, can also have negative impacts on the environment.\n",
    "\n",
    "Query: Is nuclear power plant eco-friendly?\n",
    "• They can provide a significant amount of clean energy, reducing reliance on fossil fuels and lowering carbon emissions.\n",
    "• However, the construction process may involve environmental impacts such as land displacement and water usage.\n",
    "• Nuclear power plants also produce radioactive waste that must be carefully managed and disposed of to minimize environmental risks.\n",
    "\n",
    "Answer the question below in text using about 50 words, your answer should be in bullet points.\n",
    "\n",
    "Question:\n",
    "How to stay safe during severe weather?\n",
    "\n",
    "Answer:\n",
    "• Stay informed through local news and weather alerts\n",
    "• Have a plan and practice it with your family\n",
    "• Stock up on emergency supplies\n",
    "• Evacuate if necessary\n",
    "• Stay indoors and away from windows.\n",
    "\n",
    "Query: How to stay safe during severe weather?\n",
    "• Create a severe weather plan that includes evacuation routes and emergency contact numbers.\n",
    "• Stock an emergency kit with food, water, and necessary medications.\n",
    "• Stay indoors during the storm and avoid windows and glass doors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
